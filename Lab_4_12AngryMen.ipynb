{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Codes needed for reading the files and preparing them for language model generation"
      ],
      "metadata": {
        "id": "Tnq20FdR6P00"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmx7uy3RfDMm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extact_sentences(pattern, file_path):\n",
        "  # pattern:  is the regular expression you have defined to extract sentences\n",
        "  # file_path:path to the trascript file \n",
        "\n",
        "  # key: Jury value: sentence said\n",
        "  dictionary_lines = {}\n",
        "  with open(file_path, 'r', encoding=\"unicode_escape\") as file:\n",
        "    line = file.readline()\n",
        "    while(line):\n",
        "      # this is where you will check each line\n",
        "      ###\n",
        "      ###\n",
        "      \n",
        "      line = file.readline()\n",
        "\n",
        "  # Printing the number of sentences said by each jury (just for checking)\n",
        "  for jury in dictionary_lines:\n",
        "    print(jury + \":\\t\" + str(len(dictionary_lines[jury])))\n",
        "\n",
        "def pre_process_inputs(dictionary_lines):\n",
        "  # This method takes in the dictionary from previous method\n",
        "  # It will return two dictionaries: one having all the tokens along\n",
        "  # with their frequencies (list to counter?)\n",
        "  # The other dictionary will have jury as the key (e.g., NO.2)\n",
        "  # and the values are another dictionary of {token: frequency} for each jury\n",
        "  \n",
        "  lst_all_words = []\n",
        "  dictionary_juror_words = {}\n",
        "  for jury in dictionary_lines:\n",
        "    # Here update all the words list and the dictionary for each jury\n",
        "    lst_sentences_by_jury = dictionary_lines[jury]\n",
        "    words_jorur = []\n",
        "    for sentence in lst_sentences:\n",
        "      ### Your code goes here (remove pass)\n",
        "      pass\n",
        "    dictionary_juror_words[jury] = dict(Counter(words_jorur)) \n",
        "  \n",
        "  vocabulary = dict(Counter(lst_all_words))\n",
        "  return vocabulary, dictionary_juror_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to generate languge model"
      ],
      "metadata": {
        "id": "7Fm5qb1K6VVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def unigram_lm(dic_vocabulary, dic_juror_words):\n",
        "  # This method will generate the unigram language model for each juror\n",
        "  # The return value is a dict with juror as key and value as his language model\n",
        "  # the inputs are the two dictionaries from pre_process_inputs method\n",
        "  dic_unigram_lm = {}\n",
        "\n",
        "  for jury in dic_juror_words:\n",
        "    dic_words_frequency = dic_juror_words[jury]\n",
        "    language_model = {key: 0 for key in dic_vocabulary}\n",
        "    # Here you will calculate the probabilities with MLE and add-one smoothing\n",
        "    for key in language_model:\n",
        "      ### Remove pass\n",
        "      pass\n",
        "  return dic_unigram_lm"
      ],
      "metadata": {
        "id": "GuzmtTCDfY-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to generate T-SNE plot"
      ],
      "metadata": {
        "id": "uCWp1nNQ6auL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tsne_generator(dic_unigram_lm):\n",
        "  tsne = TSNE(n_components=2)\n",
        "  lst_freq = []\n",
        "  lst_names = []\n",
        "  for juror in dic_unigram_lm:\n",
        "    lst_names.append(juror)\n",
        "    \n",
        "    # frequencies is a dictionary of token: frequencies\n",
        "    # sort this by key and then convert values to the list and append it \n",
        "    # to the lst_freq\n",
        "    frequencies = dic_unigram_lm[juror]\n",
        "    ##### \n",
        "    # Your code goes here and then remove freq=[0] and instead of [0]\n",
        "    # save your results in freq\n",
        "    freq = [0]\n",
        "    lst_freq.append(freq)\n",
        "  \n",
        "  # Convert the list to a NumPy array\n",
        "  np_array = np.array(lst_freq)\n",
        "  data = np_array\n",
        "\n",
        "  # getting vectors with tsne\n",
        "  vectors = tsne.fit_transform(data)\n",
        "\n",
        "  # Your code for plot goes here\n",
        "  # fig, ax = plt.subplots()\n",
        "  # Some codes here to define what to be shown\n",
        "  ####\n",
        "  # making sure the legend is shown (uncomment)\n",
        "  #ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
        "  #ax.grid(True)\n",
        "  #plt.show()"
      ],
      "metadata": {
        "id": "hhI1F1QQ6eDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}