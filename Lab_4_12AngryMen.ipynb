{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnq20FdR6P00"
      },
      "source": [
        "Codes needed for reading the files and preparing them for language model generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "Mmx7uy3RfDMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4afb0ab-929f-49c2-9b10-a8556a26764d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from io import FileIO\n",
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "def extact_sentences(file_path):\n",
        "  # file_path:path to the trascript file \n",
        "  remove = re.compile(\"[\\[\\(].*?[\\]\\)]|particular attention to juror NO\\. 8\")\n",
        "  replace = re.compile(\"FOREMAN:\")\n",
        "  juror_line = re.compile(\"NO\\.\\s?(\\d+):\\s+(.+?)(?=NO\\. \\d+|$)\")\n",
        "\n",
        "  # key: Jury value: sentence said\n",
        "  dictionary_lines = {}\n",
        "  with open(file_path, 'r', encoding=\"unicode_escape\") as file:\n",
        "    line = file.readline()\n",
        "    while(line):\n",
        "      line = re.sub(remove, \"\", line)\n",
        "      line = re.sub(replace, 'NO. 1:', line)\n",
        "      matched_text = re.search(juror_line, line)\n",
        "      if matched_text:\n",
        "        if matched_text.group(1) in dictionary_lines:\n",
        "          dictionary_lines[matched_text.group(1)].append(matched_text.group(2))\n",
        "        else:\n",
        "          dictionary_lines[matched_text.group(1)] = [matched_text.group(2)]\n",
        "      line = file.readline()\n",
        "\n",
        "  # Remove the intro description of each juror before Act 1\n",
        "  # No. 10 is formatted without a : \n",
        "  for juror in dictionary_lines:\n",
        "    if juror != '10':\n",
        "      del dictionary_lines[juror][:1]\n",
        "  return dictionary_lines\n",
        "\n",
        "def pre_process_inputs(dictionary_lines):\n",
        "  from collections import Counter\n",
        "  # This method takes in the dictionary from previous method\n",
        "  # It will return two dictionaries: one having all the tokens along\n",
        "  # with their frequencies (list to counter?)\n",
        "  # The other dictionary will have jury as the key (e.g., NO.2)\n",
        "  # and the values are another dictionary of {token: frequency} for each jury\n",
        "  \n",
        "  lst_all_words = []\n",
        "  dictionary_juror_words = {}\n",
        "  for jury in dictionary_lines:\n",
        "    lst_sentences_by_jury = dictionary_lines[jury]\n",
        "    words_juror = []\n",
        "    for sentence in lst_sentences_by_jury:\n",
        "      tokenizer = RegexpTokenizer(r'\\w+')\n",
        "      sentence_words = tokenizer.tokenize(sentence)\n",
        "      for tok in sentence_words:\n",
        "        words_juror.append(tok.lower())\n",
        "        lst_all_words.append(tok.lower())\n",
        "    dictionary_juror_words[jury] = dict(Counter(words_juror)) \n",
        "\n",
        "  vocabulary = dict(Counter(lst_all_words))\n",
        "  return vocabulary, dictionary_juror_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fm5qb1K6VVT"
      },
      "source": [
        "Code to generate languge model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "GuzmtTCDfY-p"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def unigram_lm(dic_vocabulary, dic_juror_words):\n",
        "  # This method will generate the unigram language model for each juror\n",
        "  # The return value is a dict with juror as key and value as his language model\n",
        "  # the inputs are the two dictionaries from pre_process_inputs method\n",
        "  dic_unigram_lm = {}\n",
        "\n",
        "  for jury in dic_juror_words:\n",
        "    dic_words_frequency = dic_juror_words[jury]\n",
        "    language_model = {key: 0 for key in dic_vocabulary}\n",
        "    # Here you will calculate the probabilities with MLE and add-one smoothing\n",
        "    for key in language_model:\n",
        "      if key in dic_words_frequency:\n",
        "        nom = dic_words_frequency[key] + 1\n",
        "        denom = dic_vocabulary[key] + 1 * len(dic_vocabulary)\n",
        "        language_model[key] = nom/denom\n",
        "    dic_unigram_lm[jury] = language_model\n",
        "  return dic_unigram_lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCWp1nNQ6auL"
      },
      "source": [
        "Code to generate T-SNE plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "hhI1F1QQ6eDS"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tsne_generator(dic_unigram_lm):\n",
        "  tsne = TSNE(n_components=2)\n",
        "  lst_freq = []\n",
        "  lst_names = []\n",
        "  for juror in dic_unigram_lm:\n",
        "    lst_names.append(juror)\n",
        "    \n",
        "    # frequencies is a dictionary of token: frequencies\n",
        "    # sort this by key and then convert values to the list and append it \n",
        "    # to the lst_freq\n",
        "    frequencies = dic_unigram_lm[juror]\n",
        "    ##### \n",
        "    # Your code goes here and then remove freq=[0] and instead of [0]\n",
        "    # save your results in freq\n",
        "    freq = [0]\n",
        "    lst_freq.append(freq)\n",
        "  \n",
        "  # Convert the list to a NumPy array\n",
        "  np_array = np.array(lst_freq)\n",
        "  data = np_array\n",
        "\n",
        "  # getting vectors with tsne\n",
        "  vectors = tsne.fit_transform(data)\n",
        "\n",
        "  # Your code for plot goes here\n",
        "  # fig, ax = plt.subplots()\n",
        "  # Some codes here to define what to be shown\n",
        "  ####\n",
        "  # making sure the legend is shown (uncomment)\n",
        "  #ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
        "  #ax.grid(True)\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITe_Ctc5o-50",
        "outputId": "790e081e-1566-4ce4-806f-fe9b2fa87d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary:  {'all': 58, 'right': 81, 'gentlemen': 7, 'let': 39, 's': 193, 'take': 18, 'our': 6, 'seats': 1, 'how': 35, 'about': 37, 'sitting': 3, 'down': 17, 'the': 315, 'gentleman': 5, 'at': 32, 'window': 15, 'is': 63, 'everybody': 3, 'here': 34, 'we': 73, 'd': 20, 'like': 41, 'to': 203, 'get': 19, 'started': 2, 'it': 174, 'find': 2, 'a': 176, 'seat': 1, 'aii': 1, 'now': 38, 'you': 256, 'can': 39, 'handle': 3, 'this': 74, 'any': 8, 'way': 10, 'want': 32, 'i': 216, 'mean': 23, 'm': 33, 'not': 54, 'going': 24, 'make': 10, 'rules': 1, 'if': 26, 'discuss': 3, 'first': 3, 'and': 88, 'then': 8, 'vote': 22, 'that': 127, 'one': 23, 'or': 15, 'see': 22, 'stand': 5, 'anybody': 4, 'doesn': 7, 't': 120, 'okay': 16, 'those': 7, 'voting': 3, 'guilty': 55, 'raise': 3, 'your': 29, 'hands': 3, 'nine': 4, 'ten': 10, 'eleven': 8, 'for': 40, 'know': 46, 'where': 13, 'are': 41, 'think': 49, 'good': 5, 'point': 11, 'have': 49, 'job': 1, 'do': 59, 'sounds': 3, 'fair': 6, 'enough': 10, 'supposing': 5, 'go': 12, 'once': 5, 'around': 8, 'table': 2, 'guess': 8, 're': 50, 'coroner': 1, 'fixed': 1, 'time': 16, 'of': 78, 'death': 1, 'midnight': 1, 'in': 62, 'order': 1, 'easy': 5, 'calm': 2, 'number': 2, '5': 2, 'turn': 4, 'privilege': 1, 'anything': 9, 'else': 9, 'be': 23, 'reasonable': 7, 'there': 25, 'nothing': 8, 'personal': 3, 'stop': 5, 'bickering': 1, 'wasting': 3, 'he': 125, 'ought': 2, 'on': 25, 'with': 33, 'everyone': 4, 'agreed': 2, 'pass': 5, 'these': 7, 'along': 2, 'hold': 2, 'man': 39, 'wants': 3, 'talk': 12, 'please': 3, 'don': 58, 'fights': 1, 'come': 10, 'sure': 6, 'three': 5, 'favor': 2, 'heard': 22, 'thank': 3, 'no': 32, 'wrong': 5, 'back': 4, 'finished': 2, 'anyone': 9, 'object': 2, 'll': 14, 'call': 3, 'off': 7, 'jury': 4, 'numbers': 1, '3': 1, '4': 1, '6': 1, '7': 1, '8': 1, '9': 1, '10': 2, '11': 1, '12': 1, 'six': 12, 'arguing': 2, 'who': 31, 'got': 21, 'something': 13, 'constructive': 1, 'say': 25, 'another': 4, 'called': 2, 'quickest': 1, 'show': 4, 'wait': 8, 'minute': 9, 'did': 25, 'she': 38, 'wear': 4, 'glasses': 6, 'remember': 6, 'well': 27, 'they': 32, 'entitled': 3, 'oh': 5, 'just': 19, 'thought': 6, 'was': 44, 'obvious': 1, 'nobody': 6, 'proved': 7, 'otherwise': 2, 've': 17, 'what': 82, 'meant': 1, 'anyway': 2, 'maybe': 24, 'didn': 15, 'hear': 10, 'el': 11, 'noise': 2, 'cough': 1, 'drop': 1, 'said': 14, 'fifteen': 12, 'twenty': 4, 'thirty': 3, 'seconds': 16, 'exactly': 4, 'been': 6, 'bothering': 1, 'me': 45, 'little': 7, 'whole': 5, 'business': 2, 'stab': 6, 'wound': 2, 'made': 5, 'downward': 2, 'angle': 2, 'but': 11, 'boy': 34, 'five': 4, 'feet': 10, 'eight': 5, 'inches': 6, 'tall': 1, 'his': 46, 'father': 20, 'two': 12, 'difference': 2, 'very': 14, 'awkward': 2, 'thing': 18, 'into': 12, 'chest': 4, 'someone': 8, 'half': 2, 'foot': 2, 'taller': 2, 'than': 6, 'look': 27, 'out': 29, 'late': 1, 'suppose': 3, 'us': 14, 'home': 6, 'finish': 1, 'morning': 1, 'kid': 22, 'mumps': 1, 'clearly': 2, 'why': 17, 'put': 3, 'my': 19, 'clock': 7, 'course': 3, 'wears': 2, 'eyeglasses': 2, 'bed': 12, 'days': 1, 'should': 4, 'ever': 10, 'so': 19, 'much': 3, 'gets': 3, 'trial': 6, 'system': 1, 'against': 2, 'somebody': 5, 'left': 3, 'field': 1, 'never': 10, 'saw': 21, 'guiltier': 1, 'life': 9, 'sat': 2, 'court': 6, 'same': 4, 'dangerous': 2, 'killer': 1, 'could': 10, 'old': 24, 'knifed': 1, 'own': 2, 'four': 1, 'an': 16, 'innocent': 2, 'nineteen': 2, 'year': 2, 'dozen': 1, 'different': 1, 'ways': 1, 'list': 1, 'them': 12, 'facts': 4, 'lived': 3, 'second': 10, 'floor': 2, 'underneath': 1, 'room': 9, 'murder': 6, 'took': 7, 'place': 6, 'minutes': 2, 'after': 6, 'twelve': 7, 'night': 11, 'killing': 7, 'loud': 2, 'noises': 1, 'upstairs': 1, 'apartment': 6, 'sounded': 1, 'fight': 3, 'gonna': 9, 'kill': 16, 'later': 5, 'body': 8, 'falling': 3, 'ran': 4, 'door': 16, 'looked': 9, 'running': 4, 'stairs': 3, 'house': 6, 'police': 1, 'found': 3, 'knife': 20, 'absolutely': 4, 'sit': 4, 'letting': 2, 'him': 32, 'upset': 1, 'relax': 1, 'kids': 4, 'listen': 13, 'when': 8, 'years': 7, 'away': 1, 'from': 12, 'ashamed': 2, 'told': 3, 'bust': 1, 'up': 24, 'pieces': 1, 'trying': 9, 'hit': 2, 'face': 2, 'big': 3, 'haven': 1, 'seen': 6, 'rotten': 1, 'work': 1, 'heart': 2, 'feller': 1, 'sensitive': 1, 'looks': 2, 'again': 10, 'bet': 2, 'knows': 3, 'talking': 5, 'pulled': 1, 'real': 3, 'smart': 2, 'trick': 1, 'zero': 1, 'knives': 3, 'lied': 7, 'whose': 1, 'fault': 1, 'holding': 1, 'chair': 3, 'belongs': 1, 'sudden': 1, 'paying': 1, 'attention': 2, 'fairy': 1, 'tales': 1, 'wouldn': 6, 'lawyer': 4, 'explain': 1, 'doubts': 1, 'mouthful': 1, 'yell': 1, 'lend': 1, 'pencil': 1, 'might': 2, 'as': 15, 'mind': 7, 'walk': 8, 'belt': 1, 'ya': 2, 'nerve': 2, 'absolute': 1, 'isn': 9, 'game': 2, 'does': 9, 'yelled': 1, 'people': 8, 'calling': 1, 'liar': 1, 'crazy': 2, 'would': 7, 'lie': 3, 'gain': 2, 'keep': 2, 'coming': 1, 'bright': 2, 'sayings': 1, 'send': 2, 'newspaper': 1, 'pay': 1, 'dollars': 2, 'most': 6, 'fantastic': 1, 'story': 6, 'phrase': 2, 'screamed': 1, 'top': 2, 'lungs': 1, 'try': 6, 'tell': 14, 'says': 5, 'only': 10, 'exhibits': 2, 'long': 7, 'judge': 2, 'kind': 4, 'confused': 1, 'positive': 2, 'sound': 2, 'doing': 2, 'recreate': 2, 'assumed': 2, 'kinds': 1, 'dishonesty': 2, 'day': 6, 'display': 1, 'takes': 4, 'cake': 1, 'will': 3, 'bleeding': 1, 'over': 11, 'slum': 4, 'injustice': 1, 'wild': 2, 'stories': 3, 'some': 5, 'softhearted': 1, 'ladies': 1, 'listening': 1, 'getting': 3, 'sick': 2, 'matter': 5, 'burn': 1, 'slip': 1, 'through': 8, 'fingers': 2, 'em': 4, 'pull': 4, 'switch': 8, 'start': 7, 'shut': 3, 'looking': 1, 'open': 8, 'ballot': 3, 'votes': 3, 'stands': 2, 'ready': 2, 'declare': 1, 'hung': 1, 'more': 7, 'went': 8, 'satisfied': 1, 'till': 1, 'give': 2, 'demonstration': 1, 'watch': 2, 'hurt': 3, 'done': 2, 'silly': 1, 'common': 2, 'sense': 1, 'asking': 2, 'had': 16, 'answer': 4, 'far': 7, 'concerned': 2, 'important': 5, 'testimony': 6, 'case': 3, 'throw': 1, 'other': 3, 'evidence': 5, 'grandmother': 2, 'sighted': 1, 'things': 3, 'care': 2, 'whether': 3, 'alone': 7, 'gave': 2, 'arguments': 3, 'guy': 6, 'walking': 1, 'streets': 1, 'murderer': 1, 'die': 4, 'stay': 1, 'intimidate': 1, 'opinion': 1, 'need': 2, 'able': 1, 'behave': 2, 'entire': 1, 'flimsy': 1, 'claimed': 2, 'movies': 2, 'ridiculous': 1, 'couldn': 6, 'even': 8, 'pictures': 1, 'missing': 1, 'product': 1, 'filthy': 1, 'neighborhood': 3, 'broken': 1, 'help': 2, 'reasons': 2, 'slums': 1, 'breeding': 1, 'grounds': 1, 'criminals': 1, 'children': 2, 'backgrounds': 1, 'potential': 1, 'menaces': 1, 'society': 1, 'has': 6, 'pretty': 4, 'strong': 3, 'piece': 1, 'agree': 1, 'admits': 1, 'o': 5, 'being': 1, 'slapped': 1, 'by': 8, 'punched': 2, 'store': 1, 'bought': 1, 'storekeeper': 3, 'arrested': 2, 'following': 1, 'admitted': 1, 'selling': 1, 'unusual': 1, 'identified': 2, 'its': 1, 'stock': 1, 'present': 1, 'friend': 1, 'am': 4, 'next': 3, 'claims': 1, 'must': 3, 'fallen': 1, 'hole': 2, 'coat': 1, 'pocket': 2, 'actually': 2, 'happened': 1, 'few': 6, 'hours': 1, 'stabbed': 6, 'remembered': 2, 'wipe': 1, 'fingerprints': 1, 'connected': 1, 'picked': 2, 'street': 8, 'amusing': 1, 'strange': 1, 'before': 5, 'neither': 2, 'sold': 1, 'aren': 2, 'accept': 1, 'incredible': 1, 'coincidence': 1, 'ask': 5, '1': 3, 'understand': 6, 'word': 3, 'woman': 10, 'windows': 5, 'moving': 1, 'elevated': 3, 'train': 7, 'cars': 3, 'last': 4, 'remembers': 1, 'insignificant': 2, 'details': 1, 'slightest': 1, 'idea': 3, 'bedroom': 8, 'front': 6, 'wading': 1, 'nonsense': 1, 'mouth': 2, 'split': 3, 'skull': 1, 'still': 7, 'believe': 13, 'damning': 1, 'given': 5, 'across': 9, 'committed': 1, 'recount': 1, 'accurately': 1, 'her': 7, 'while': 3, 'lying': 2, 'directly': 2, 'tossed': 1, 'turned': 2, 'hour': 1, 'unable': 1, 'fall': 4, 'asleep': 1, 'finally': 1, 'toward': 1, 'unshakable': 1, 'frankly': 1, 'acquittal': 1, 'feeling': 5, 'funny': 3, 'sorry': 3, 'doubt': 5, 'knew': 1, 'locked': 1, 'occurred': 1, 'used': 5, 'play': 2, 'yard': 2, 'filled': 1, 'garbage': 1, 'smells': 1, 'forced': 2, 'reason': 4, 'change': 5, 'lawyers': 1, 'everything': 3, 'run': 5, 'too': 5, 'came': 4, 'tips': 1, 'learned': 1, 'perfect': 1, 'yes': 1, 'stoop': 1, 'vacant': 1, 'lot': 2, 'many': 3, 'forget': 3, 'use': 1, 'underhanded': 1, 'experience': 2, 'chance': 1, 'convinced': 3, 'hall': 7, 'argument': 2, 'between': 1, 'seven': 3, 'prove': 4, 'part': 2, 'picture': 1, 'possible': 6, 'mr': 4, 'foreman': 4, 'pardon': 2, 'without': 2, 'may': 5, 'dumb': 1, 'wake': 2, 'thinking': 2, 'testified': 2, 'y': 1, 'hot': 3, 'least': 2, 'air': 2, 'condition': 1, 'almost': 3, 'dropped': 1, 'dead': 3, 'phonier': 1, 'yeah': 4, 'cold': 1, 'lulu': 1, 'weather': 1, 'colds': 1, 'better': 3, 'fast': 4, 'tickets': 2, 'itch': 1, 'tonight': 1, 'world': 1, 'hasn': 1, 'yet': 1, 'honor': 1, 'because': 6, 'voted': 2, 'talked': 1, 'hundred': 1, 'already': 2, 'record': 1, 'reform': 2, 'school': 2, 'stole': 1, 'car': 2, 'mugging': 1, 'fighting': 2, 'arm': 2, 'fine': 2, 'accomplish': 1, 'stubborn': 1, 'hang': 1, 'tried': 1, 'born': 2, 'stick': 2, 'subject': 1, 'phone': 1, 'end': 1, 'basing': 1, 'oughta': 1, 'write': 1, 'american': 1, 'detective': 1, 'monthly': 1, 'fortune': 1, 'bring': 1, 'points': 1, 'brother': 1, 'thin': 1, 'supposed': 3, 'beat': 2, 'downstairs': 1, 'saying': 2, 'walked': 3, 'straight': 1, 'chances': 1, 'guys': 1, 'comes': 1, 'breath': 1, 'telling': 2, 'arrogance': 1, 'apologize': 1, 'nowhere': 2, 'break': 1, 'changing': 1, 'l': 2, 'were': 3, 'hand': 3, 'kicked': 1, 'living': 2, 'mother': 1, 'since': 3, 'head': 2, 'tough': 2, 'angry': 1, 'knock': 1, 'every': 2, 'owe': 2, 'words': 2, 'burden': 1, 'proof': 1, 'prosecution': 1, 'defendant': 1, 'constitution': 1, 'fifth': 1, 'amendment': 1, 'passing': 2, 'believed': 1, 'twice': 2, 'angrily': 1, 'regularly': 1, 'fists': 1, 'peculiar': 1, 'somehow': 1, 'felt': 1, 'defense': 1, 'counsel': 1, 'really': 4, 'conducted': 1, 'thorough': 1, 'cross': 1, 'examination': 1, 'appointed': 1, 'defend': 1, 'hardly': 1, 'seemed': 1, 'interested': 1, 'questions': 1, 'unasked': 1, 'lost': 1, 'similar': 1, 'junk': 1, 'shop': 1, 'corner': 1, 'cost': 2, 'probably': 2, 'proposition': 1, 'men': 1, 'secret': 3, 'abstain': 1, 'won': 1, 'verdict': 3, 'decide': 2, 'motives': 1, 'sketch': 1, 'speed': 2, 'passes': 1, 'which': 3, 'reach': 1, 'touch': 1, 'live': 1, 'tracks': 3, 'goes': 1, 'unbearable': 1, 'yourself': 2, 'per': 1, 'fell': 1, 'according': 2, 'roaring': 1, 'past': 2, 'nose': 1, 'nave': 1, 'thanks': 1, 'times': 1, 'each': 2, 'hundreds': 1, 'junior': 1, 'rocky': 1, 'diagram': 1, 'strokes': 1, 'walks': 1, 'pair': 1, 'canes': 5, 'beneath': 1, 'bathroom': 1, 'kitchen': 1, 'steps': 1, 'opened': 1, 'racing': 2, 'length': 3, 'forty': 3, 'pace': 1, 'close': 2, 'shorter': 1, 'spare': 1, 'stamp': 1, 'keeps': 1, 'bedside': 1, 'faster': 1, 'executioner': 1, 'perhaps': 5, 'feel': 1, 'sadist': 1, 'personally': 1, 'information': 1, 'experienced': 1, 'fighter': 1, 'sent': 1, 'knifing': 1, 'seem': 1, 'killed': 3, 'witness': 2, 'wasn': 1, 'wearing': 1, 'midst': 1, 'tossing': 1, 'turning': 1, 'rolled': 1, 'casually': 1, 'taking': 1, 'lights': 1, 'honestly': 1, 'blur': 1, 'waiting': 3, 'except': 1, 'hope': 1, 'months': 1, 'sleep': 2, 'forgive': 1, 'terrible': 2, 'group': 1, 'characteristic': 1, 'monopoly': 1, 'truth': 2, 'chose': 1, 'great': 2, 'deal': 2, 'courage': 2, 'strongly': 1, 'gambled': 1, 'support': 1, 'beyond': 1, 'seam': 1, 'jacket': 2, 'under': 1, 'notice': 1, 'torn': 1, 'carried': 1, 'quiet': 1, 'frightened': 1, 'recognition': 1, 'name': 1, 'newspapers': 1, 'seventy': 1, 'sad': 1, 'needs': 1, 'recognized': 2, 'questioned': 1, 'listened': 1, 'quoted': 1, 'himself': 1, 'speak': 3, 'uses': 1, 'bifocals': 2, 'sensitivity': 1, 'excuse': 1, 'remain': 1, 'always': 1, 'unpopular': 1, 'opinions': 1, 'country': 3, 'wanted': 1, 'disagree': 1, 'english': 2, 'correct': 1, 'slowly': 1, 'quickly': 1, 'courtroom': 1, 'nor': 1, 'responsibility': 1, 'remarkable': 1, 'democracy': 1, 'ummmm': 1, 'ah': 1, 'notified': 2, 'mail': 1, 'guilt': 1, 'innocence': 1, 'known': 3, 'lose': 1, 'beg': 1, 'term': 1, 'theater': 1, 'burning': 1, 'changed': 1, 'ugly': 1, 'guts': 2, '1s': 1, 'wore': 1, 'quite': 1, 'inside': 1, 'seems': 1, 'convince': 1, 'sort': 1, 'size': 1, 'spitball': 1, 'sift': 1, 'lock': 1, 'gotta': 1, 'expect': 1, 'dealing': 1, 'figure': 1, 'kills': 1, 'bing': 1, 'element': 1, 'serves': 1, 'mister': 1, 'lucky': 1, 'grownups': 1, 'knowing': 1, 'among': 1, 'sees': 1, 'opposite': 1, 'hers': 1, 'swore': 1, 'happening': 1, 'side': 1, 'fellow': 1, 'force': 1, 'history': 1, 'speech': 1, 'spend': 1, 'feelings': 2, 'giving': 2, 'ignorant': 1, 'slob': 1, 'somewhere': 1, 'insane': 1, 'makes': 1, 'mumbo': 1, 'jumbo': 1, 'lemme': 1, 'either': 1, 'human': 1, 'hey': 1, 'drinking': 1, 'decent': 1, 'exception': 1}\n"
          ]
        }
      ],
      "source": [
        "path = r\"/content/12AngryMen.txt\"\n",
        "\n",
        "dictionary_lines = extact_sentences(path)\n",
        "\n",
        "#for juror in dictionary_lines:\n",
        "  #print(\"Juror No.\", juror, \" Lines: \", len(dictionary_lines[juror]))\n",
        "\n",
        "vocabulary, dictionary_juror_words = pre_process_inputs(dictionary_lines)\n",
        "\n",
        "print(\"Vocabulary: \", vocabulary)\n",
        "#print(\"Juror_words\", dictionary_juror_words)\n",
        "language_models = unigram_lm(vocabulary, dictionary_juror_words)\n",
        "#for juror in language_models:\n",
        "  #print(\"Juror No.\", juror, \" Probability of word: \", language_models[juror])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}