{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnq20FdR6P00"
      },
      "source": [
        "Codes needed for reading the files and preparing them for language model generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mmx7uy3RfDMm"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.8.11 ('base')' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def extact_sentences(pattern, file_path):\n",
        "  # pattern:  is the regular expression you have defined to extract sentences\n",
        "  # file_path:path to the trascript file \n",
        "\n",
        "  # key: Jury value: sentence said\n",
        "  dictionary_lines = {}\n",
        "  with open(file_path, 'r', encoding=\"unicode_escape\") as file:\n",
        "    line = file.readline()\n",
        "    while(line):\n",
        "      line = re.sub(r\"[\\[\\(].*?[\\]\\)]\", \"\", line)\n",
        "      line = re.sub(r'FOREMAN:', 'NO. 1:', line)\n",
        "      matched_text = re.search(r'NO\\.\\s?(\\d+):\\s+(.+?)(?=NO\\. \\d+|$', line)\n",
        "      if matched_text is not None:\n",
        "        if matched_text.group(1) in dictionary_lines:\n",
        "          dictionary_lines[matched_text.group(1)].append(matched_text.group(2))\n",
        "        else:\n",
        "          dictionary_lines[matched_text.group(1)] = [matched_text.group(2)]\n",
        "      \n",
        "      line = file.readline()\n",
        "\n",
        "  # Printing the number of sentences said by each jury (just for checking)\n",
        "  for jury in dictionary_lines:\n",
        "    print(jury + \":\\t\" + str(len(dictionary_lines[jury])))\n",
        "\n",
        "def pre_process_inputs(dictionary_lines):\n",
        "  # This method takes in the dictionary from previous method\n",
        "  # It will return two dictionaries: one having all the tokens along\n",
        "  # with their frequencies (list to counter?)\n",
        "  # The other dictionary will have jury as the key (e.g., NO.2)\n",
        "  # and the values are another dictionary of {token: frequency} for each jury\n",
        "  \n",
        "  lst_all_words = []\n",
        "  dictionary_juror_words = {}\n",
        "  for jury in dictionary_lines:\n",
        "    # Here update all the words list and the dictionary for each jury\n",
        "    lst_sentences_by_jury = dictionary_lines[jury]\n",
        "    words_jorur = []\n",
        "    for sentence in lst_sentences:\n",
        "      ### Your code goes here (remove pass)\n",
        "      pass\n",
        "    dictionary_juror_words[jury] = dict(Counter(words_jorur)) \n",
        "  \n",
        "  vocabulary = dict(Counter(lst_all_words))\n",
        "  return vocabulary, dictionary_juror_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fm5qb1K6VVT"
      },
      "source": [
        "Code to generate languge model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuzmtTCDfY-p"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def unigram_lm(dic_vocabulary, dic_juror_words):\n",
        "  # This method will generate the unigram language model for each juror\n",
        "  # The return value is a dict with juror as key and value as his language model\n",
        "  # the inputs are the two dictionaries from pre_process_inputs method\n",
        "  dic_unigram_lm = {}\n",
        "\n",
        "  for jury in dic_juror_words:\n",
        "    dic_words_frequency = dic_juror_words[jury]\n",
        "    language_model = {key: 0 for key in dic_vocabulary}\n",
        "    # Here you will calculate the probabilities with MLE and add-one smoothing\n",
        "    for key in language_model:\n",
        "      ### Remove pass\n",
        "      pass\n",
        "  return dic_unigram_lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCWp1nNQ6auL"
      },
      "source": [
        "Code to generate T-SNE plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhI1F1QQ6eDS"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tsne_generator(dic_unigram_lm):\n",
        "  tsne = TSNE(n_components=2)\n",
        "  lst_freq = []\n",
        "  lst_names = []\n",
        "  for juror in dic_unigram_lm:\n",
        "    lst_names.append(juror)\n",
        "    \n",
        "    # frequencies is a dictionary of token: frequencies\n",
        "    # sort this by key and then convert values to the list and append it \n",
        "    # to the lst_freq\n",
        "    frequencies = dic_unigram_lm[juror]\n",
        "    ##### \n",
        "    # Your code goes here and then remove freq=[0] and instead of [0]\n",
        "    # save your results in freq\n",
        "    freq = [0]\n",
        "    lst_freq.append(freq)\n",
        "  \n",
        "  # Convert the list to a NumPy array\n",
        "  np_array = np.array(lst_freq)\n",
        "  data = np_array\n",
        "\n",
        "  # getting vectors with tsne\n",
        "  vectors = tsne.fit_transform(data)\n",
        "\n",
        "  # Your code for plot goes here\n",
        "  # fig, ax = plt.subplots()\n",
        "  # Some codes here to define what to be shown\n",
        "  ####\n",
        "  # making sure the legend is shown (uncomment)\n",
        "  #ax.legend(bbox_to_anchor=(1.1, 1.05))\n",
        "  #ax.grid(True)\n",
        "  #plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "25f700ecede64609a4a6a94bdf512b7586669e6feb88b6e4d379f65cb5ef9ca9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
